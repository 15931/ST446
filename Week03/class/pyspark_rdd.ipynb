{"nbformat_minor":4,"cells":[{"cell_type":"markdown","metadata":{},"source":["# ST446 Distributed Computing for Big Data\n","\n","## Seminar class 3: getting started with PySpark\n","\n","In this exercise, we are going to create and perform various transformations of resilient distributed datasets (RDD) in PySpark.\n","\n","**Note: Make sure you open jupyter using command `pyspark` not `jupyter notebook`! \n","You can switch between Python and PySpark via the menu item \"Kernel/Change Kernel\".**"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Creating RDDs"]},{"cell_type":"markdown","metadata":{},"source":["There are two ways to create an RDD in PySpark:\n","\n","### a) parallelize a list"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', 1), ('b', 4), ('c', 10)]"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = sc.parallelize([('a', 1), ('b', 4), ('c',10)])\n","data.collect()"]},{"cell_type":"markdown","metadata":{},"source":["or\n","\n","### b) read from a data source (a file or a database)\n","\n","We can use `textFile` function to fetch the files in our bucket.\n","First copy `author-large.txt` in the gcp master host to the bucket, then run the following command"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# edit location\n","data_from_file = sc.\\\n","    textFile(\n","        \"gs://jialin-bucket/author-large.txt\", \n","        4)"]},{"cell_type":"markdown","metadata":{},"source":["You should change the path to where the file is.\n","\n","When you read from a text file, each row from the file forms an element of the RDD.\n","\n","But what does `sc` mean? It's the Spark context. SparkContext (aka Spark context) is the heart of a Spark application. It's the thing that connects you to the spark execution environment, i.e., it coordinates what's going on behind the scenes."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":"[u'Jurgen Annevelink\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n u'Rafiul Ahad\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n u'Amelia Carlson\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n u'Daniel H. Fishman\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n u'Michael L. Heytens\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995']"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data_from_file.take(5)"]},{"cell_type":"markdown","metadata":{},"source":["Looks familiar?"]},{"cell_type":"markdown","metadata":{},"source":["### Schema"]},{"cell_type":"markdown","metadata":{},"source":["RDD is a *schema-less* data structure."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":"[('Ferrari', 'fast'), {'Porsche': 100000}, ['Spain', 'visited', 4504]]"},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data_heterogenous = sc.parallelize([('Ferrari', 'fast'), {'Porsche': 100000}, ['Spain','visited', 4504]]).collect()\n","data_heterogenous"]},{"cell_type":"markdown","metadata":{},"source":["You can access the object that stored in an RDD element as you would normally do in Python."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":"100000"},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data_heterogenous[1]['Porsche']"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Transformations"]},{"cell_type":"markdown","metadata":{},"source":["### a) .map(...)"]},{"cell_type":"markdown","metadata":{},"source":[".map applies (...) to each element of the RDD. Here we transform each row of the `data_from_file` from a string to a list of strings."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":"[array([u'Jurgen Annevelink', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Rafiul Ahad', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Amelia Carlson', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Daniel H. Fishman', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Michael L. Heytens', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78')]"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["def extractInformation(row):\n","    import re\n","    import numpy as np\n","    \n","    row = row.strip() # remove leading and trailing whitespaces\n","    words = np.array(row.split(\"\\t\")) # split the line into words by tab\n","    return words\n","\n","data_from_file_conv = data_from_file.map(extractInformation)\n","data_from_file_conv.map(lambda row: row).take(5)"]},{"cell_type":"markdown","metadata":{},"source":["Or we can use a lambda expression to split and transform our dataset. You should get the same result as above."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":"[array([u'Jurgen Annevelink', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Rafiul Ahad', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Amelia Carlson', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Daniel H. Fishman', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78'),\n array([u'Michael L. Heytens', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78')]"},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","data_from_file_conv = data_from_file.map(lambda row: np.array(row.strip().split(\"\\t\")))\n","data_from_file_conv.take(5)"]},{"cell_type":"markdown","metadata":{},"source":["We can filter and transform only one part of an RDD element: "]},{"cell_type":"code","execution_count":11,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":"[1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995]"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["publish_year = data_from_file_conv.map(lambda row: int(row[3]))\n","publish_year.take(10)"]},{"cell_type":"markdown","metadata":{},"source":["or, we can combine multiple part of an RDD element:"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":"[(u'Jurgen Annevelink',\n  u'Object SQL - A Language for the Design and Implementation of Object Databases.'),\n (u'Rafiul Ahad',\n  u'Object SQL - A Language for the Design and Implementation of Object Databases.'),\n (u'Amelia Carlson',\n  u'Object SQL - A Language for the Design and Implementation of Object Databases.'),\n (u'Daniel H. Fishman',\n  u'Object SQL - A Language for the Design and Implementation of Object Databases.'),\n (u'Michael L. Heytens',\n  u'Object SQL - A Language for the Design and Implementation of Object Databases.')]"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["author_book = data_from_file_conv.map(lambda row: (row[0], row[2]))\n","author_book.take(5)"]},{"cell_type":"markdown","metadata":{},"source":["### .flatMap(...)"]},{"cell_type":"markdown","metadata":{},"source":["The `.flatMap(...)` method works similarly to `.map(...)` but returns a flattened result instead of a list. "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":"[u'Jurgen Annevelink',\n u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n u'Rafiul Ahad',\n u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n u'Amelia Carlson',\n u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n u'Daniel H. Fishman',\n u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n u'Michael L. Heytens',\n u'Object SQL - A Language for the Design and Implementation of Object Databases.']"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["publish_year_2_flat = data_from_file_conv.flatMap(lambda row: (row[0], row[2]))\n","publish_year_2_flat.take(10)"]},{"cell_type":"markdown","metadata":{},"source":["### b) .filter(...)"]},{"cell_type":"markdown","metadata":{},"source":["The `.filter(...)` method allows us to select elements of an RDD that statisfy specified criteria. Here we filter all the elements with author name 'Hans-Peter Seidel'."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":"[array([u'Hans-Peter Seidel', u'3DIM',\n        u'Accuracy of 3D Range Scanners by Measurement of the Slanted Edge Modulation Transfer Function.',\n        u'2003'], dtype='<U94'), array([u'Hans-Peter Seidel', u'3DPVT',\n        u'A Statistical Method for Robust 3D Surface Reconstruction from Sparse Data.',\n        u'2004'], dtype='<U75'), array([u'Hans-Peter Seidel', u'3DPVT', u'Neural Mesh Ensembles.', u'2004'],\n       dtype='<U22'), array([u'Hans-Peter Seidel',\n        u'IEEE Workshop on Multimedia Signal Processing',\n        u'Combining stereo and visual hull information for on-line reconstruction and rendering of dynamic scenes.',\n        u'2002'], dtype='<U104'), array([u'Hans-Peter Seidel', u'AMDO',\n        u'Modeling Relaxed Hand Shape for Character Animation.', u'2006'],\n       dtype='<U52')]"},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data_filtered = data_from_file_conv.filter(lambda row: row[0] == 'Hans-Peter Seidel') \n","data_filtered.take(5)"]},{"cell_type":"markdown","metadata":{},"source":["### c) .distinct()"]},{"cell_type":"markdown","metadata":{},"source":["This method returns a list of distinct values of transformed RDD elements."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":"581765"},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["distinct_author = data_from_file_conv.map(lambda row: row[0]).distinct()\n","distinct_author.count()"]},{"cell_type":"markdown","metadata":{},"source":["### d) .sample(...)"]},{"cell_type":"markdown","metadata":{},"source":["The `.sample()` method returns a random subset of an RDD."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":"[array([u'Daniel H. Fishman', u'Modern Database Systems',\n        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n        u'1995'], dtype='<U78')]"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["fraction = 0.1\n","data_sample = data_from_file_conv.sample(False, fraction, 666)\n","\n","data_sample.take(1)"]},{"cell_type":"markdown","metadata":{},"source":["Let's confirm that we really got 10% of all the elements."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"('Original dataset: ', 2225370)\n('Sample', 222417)\n('Ratio', 0.09994607638280376)\n"}],"source":["length_original = data_from_file_conv.count()\n","length_sample = data_sample.count()\n","print('Original dataset: ', length_original) \n","print('Sample', length_sample)\n","print('Ratio', length_sample*1.0/length_original)"]},{"cell_type":"markdown","metadata":{},"source":["### e) Join\n","\n","Here we demonstrate the join operation for two pair RDDs:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["rdd1 = sc.parallelize([('a', 1), ('b', 4), ('c',10)])\n","rdd2 = sc.parallelize([('a', 1), ('b', 6), ('d', 15),('d', 3),('e', 2),('a', 8),('d', 2),('e', 1),('f', 3)])"]},{"cell_type":"markdown","metadata":{},"source":["#### .leftOuterJoin(...)\n","\n","Left outer join, just like in SQL, joins two pair RDDs (left and right) based on their keys. For each key of the left RDD, it returns the corresponding value of the left RDD and the value of the right RDD if there there is a matching key (otherwise a null value)."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', (1, 1)), ('a', (1, 8)), ('c', (10, None)), ('b', (4, 6))]"},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["rdd1.leftOuterJoin(rdd2).collect()"]},{"cell_type":"markdown","metadata":{},"source":["#### .join(...)\n","\n","If we used `.join(...)` method instead we would have gotten only the values for `'a'` and `'b'` as these two values intersect between these two RDDs."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', (1, 1)), ('a', (1, 8)), ('b', (4, 6))]"},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["rdd1.join(rdd2).collect()"]},{"cell_type":"markdown","metadata":{},"source":["#### .intersection(...)\n","\n","Another useful method is the `.intersection(...)` that returns elements that are in both RDDs."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', 1)]"},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["rdd1.intersection(rdd2).collect()"]},{"cell_type":"markdown","metadata":{},"source":["### f) .repartition(...)"]},{"cell_type":"markdown","metadata":{},"source":["Repartitioning a dataset changes the number of partitions the dataset is divided into."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"('before repartition:', 2)\n('after repartition:', 4)\n"}],"source":["print('before repartition:', len(rdd1.glom().collect()))\n","rdd1 = rdd1.repartition(4)\n","\n","print('after repartition:', len(rdd1.glom().collect()))"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Actions"]},{"cell_type":"markdown","metadata":{},"source":["### a) .take(...)"]},{"cell_type":"markdown","metadata":{},"source":["The method returns specified number of top elements from a single dataset partition."]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":"[('b', 4)]"},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["data_first = rdd1.take(1)\n","data_first"]},{"cell_type":"markdown","metadata":{},"source":["####  .takeSample(...)\n","If we want to get a pseudo random subset of elements, we can use `.takeSample(...)` instead."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":"[('c', 10)]"},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["data_take_sampled = rdd1.takeSample(False, 1, 667)\n","data_take_sampled"]},{"cell_type":"markdown","metadata":{},"source":["### b) .reduce(...)"]},{"cell_type":"markdown","metadata":{},"source":["The method `.reduce(...)` *reduces* the elements of an RDD using a specified function."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"9.0\n"}],"source":["data_reduce_1 = sc.parallelize([1, 2., .5, .3, 5, .2], 1)\n","print(data_reduce_1.reduce(lambda x, y: x + y))"]},{"cell_type":"markdown","metadata":{},"source":["Even if we partition the dataset in a different way, we still get the same result because the given reduce function is associative and commutative."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"9.0\n"}],"source":["data_reduce_2 = sc.parallelize([1, 2., .5, .3, 5, .2], 3)\n","print(data_reduce_2.reduce(lambda x, y: x + y))"]},{"cell_type":"markdown","metadata":{},"source":["If the reduce function is not associative and commutative, you may get a wrong result depending on how your data is partitioned."]},{"cell_type":"markdown","metadata":{},"source":["For example, if we were to reduce the data by *dividing* the current result with the input element, we should obtain 3.33... as the result."]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.33333333333\n"}],"source":["print(data_reduce_1.reduce(lambda x, y: x / y))"]},{"cell_type":"markdown","metadata":{},"source":["However, if the dataset is partitioned into 3 partitions, the result will be incorrect. Why?"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.012\n"}],"source":["print(data_reduce_2.reduce(lambda x, y: x / y))"]},{"cell_type":"markdown","metadata":{},"source":["#### .reduceByKey(...)\n","\n","The `.reduceByKey(...)` method works in a similar way to the `.reduce(...)` method but performs a reduction per distinct key."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', 9), ('e', 3), ('b', 6), ('d', 20), ('f', 3)]"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["rdd2.reduceByKey(lambda x, y: x + y).collect()"]},{"cell_type":"markdown","metadata":{},"source":["### c) .count()"]},{"cell_type":"markdown","metadata":{},"source":["The `.count()` method counts the number of elements in the RDD."]},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":"9"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["rdd2.count()"]},{"cell_type":"markdown","metadata":{},"source":["It has the same effect as the method below but does not require shifting the data to the driver node."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":"9"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(rdd2.collect()) # DON'T DO THIS - it is expensive!"]},{"cell_type":"markdown","metadata":{},"source":["If your dataset is in the form of *key-value* you can use the `.countByKey()` method to get the counts for distinct keys."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":"[('a', 2), ('b', 1), ('e', 2), ('d', 3), ('f', 1)]"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["rdd2.countByKey().items()"]},{"cell_type":"markdown","metadata":{},"source":["### d) .saveAsTextFile(...)"]},{"cell_type":"markdown","metadata":{},"source":["As the name suggests, the `.saveAsTextFile()` saves the RDD to text files: each partition to a separate file."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["my_filename = 'gs://jialin-bucket/rdd3'\n","rdd2.saveAsTextFile(my_filename)"]},{"cell_type":"markdown","metadata":{},"source":["To read the file, you need to parse as all elements are interpreted as strings."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":"[(u'a', 1),\n (u'b', 6),\n (u'd', 15),\n (u'd', 3),\n (u'e', 2),\n (u'a', 8),\n (u'd', 2),\n (u'e', 1),\n (u'f', 3)]"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["def parseInput(row):\n","    import re\n","    \n","    pattern = re.compile(r'\\(\\'([a-z])\\', ([0-9]+)\\)')\n","    row_split = pattern.split(row)\n","    return (row_split[1], int(row_split[2]))\n","    \n","data_key_reread = sc \\\n","    .textFile(my_filename) \\\n","    .map(parseInput)\n","data_key_reread.collect()"]},{"cell_type":"markdown","metadata":{},"source":["### e) .foreach(...)"]},{"cell_type":"markdown","metadata":{},"source":["The method `.foreach(...)` applies the same function to each element of the RDD in an iterative way. The difference from map is it returns nothing."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def f(x): \n","    print(x)\n","\n","data_reduce_1.foreach(f) # you won't see the output here as `print(...)` is applied to each RDD element"]},{"cell_type":"markdown","metadata":{},"source":["# Let's see how partitions change the speed"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["size = 1000\n","bigrdd = data_from_file_conv.map(lambda row: row[0])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Number of partitions: 25\n('time: ', 29.64565110206604)\nNumber of partitions: 24\n('time: ', 7.6920459270477295)\nNumber of partitions: 23\n('time: ', 7.327723026275635)\nNumber of partitions: 22\n('time: ', 6.548742055892944)\nNumber of partitions: 21\n('time: ', 6.574919939041138)\nNumber of partitions: 20\n('time: ', 6.419106960296631)\nNumber of partitions: 19\n('time: ', 6.5730390548706055)\nNumber of partitions: 18\n('time: ', 6.555976152420044)\nNumber of partitions: 17\n('time: ', 6.653263807296753)\nNumber of partitions: 16\n('time: ', 6.516002893447876)\nNumber of partitions: 15\n('time: ', 6.342061996459961)\nNumber of partitions: 14\n('time: ', 6.277467966079712)\nNumber of partitions: 13\n('time: ', 6.6794350147247314)\nNumber of partitions: 12\n('time: ', 6.260401010513306)\nNumber of partitions: 11\n('time: ', 6.317389011383057)\nNumber of partitions: 10\n('time: ', 6.282149076461792)\nNumber of partitions: 9\n('time: ', 6.6583051681518555)\nNumber of partitions: 8\n('time: ', 6.543514966964722)\nNumber of partitions: 7\n('time: ', 6.126521825790405)\nNumber of partitions: 6\n('time: ', 6.119557857513428)\nNumber of partitions: 5\n('time: ', 7.174055099487305)\nNumber of partitions: 4\n('time: ', 6.194638967514038)\nNumber of partitions: 3\n('time: ', 6.26439905166626)\nNumber of partitions: 2\n('time: ', 6.229162931442261)\nNumber of partitions: 1\n('time: ', 11.119096040725708)\n"}],"source":["import time\n","from numpy import sqrt, array, sin\n","times = []\n","\n","for npart in range(25,0,-1):\n","    bigrdd = bigrdd.repartition(npart)\n","    print(\"Number of partitions: {}\".format(bigrdd.getNumPartitions()))\n","    t0 = time.time()\n","    a0 = bigrdd.takeSample(True, size, 123);\n","    dt = time.time() - t0;\n","    print(\"time: \",dt)\n","    times = times + [dt]"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"image/png":"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\n","text/plain":"<matplotlib.figure.Figure at 0x7f329ee73310>"},"metadata":{},"output_type":"display_data"}],"source":["times = array(times)\n","from matplotlib import pyplot as plt\n","plt.plot(range(25,0,-1),times,'ko')\n","plt.xlabel(\"number of partions\")\n","plt.ylabel(\"time\")\n","plt.ylim([0,8.5])\n","plt.show();"]},{"cell_type":"markdown","metadata":{},"source":["There's some interesting structure here. Too few or too many partitions generally slow down the code."]}],"nbformat":4,"metadata":{"kernelspec":{"display_name":"PySpark","name":"pyspark","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","version":"2.7.14","name":"python","file_extension":".py","pygments_lexer":"ipython2","codemirror_mode":{"version":2,"name":"ipython"}},"anaconda-cloud":{}}}